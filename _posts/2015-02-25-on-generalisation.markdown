---
layout: post
title:  "On Generalisation in Neural Networks"
date:   2016-03-05
description: "How can a neural network generalise on data?"
---
In Supervised Learning (SL), we aim to evaluate the accuracy of a model on previously unseen data. Learning Algorithms (LA) perform on a finite set of samples and are therefore sensitive to sampling error. The functions which are estimated using a Neural Network (NN) are unknown. All we have is a training set which gives us examples of this hidden function of nature. The role of the NN is to identify this hidden function given only the training data. However, if we only train the model on the training data we are not going to model the underlying function but instead model the specific noise of this data set. The model will be more complex than necessary and is overfitting the training data. In order to avoid this, our LA is going to estimate the parameters of the function so that it replicates the data well but also generalises well to data it has never seen before. Having said this, if we keep on using the same data in our test set we are again going to choose hyper-parameters of our model, such as the learning rate, tuned to our test set. In order to avoid such a bias, it is very common to work with three different data sets. The training set which is used to adjust the parameters of our model, the validation set which is used during training to evaluate the performance of the model on unseen data, and the test set which is only used once in order to provide a genuine performance evaluation. 

![A visualisation of early stopping.](/images/early_stopping.bmp){: .center-image }

In order to find a model with high accuracy, we are going to train the model over several iterations and continuously evaluate their performance on the training set, as well as, the validation set. The image visualises the accuracy of a NN on its training set and validation set. Since the NN is initialized with small random values the error on both sets are at the beginning very high. After the first few iterations, we can see how the accuracy on the training set, as well as, the test set starts to decrease. Thus, the NN starts to generalise the underlying function better and better. However, after some time, we can observe how the training error continuously decreases while the validation error suddenly starts to increase. This means that our NN is starting to model the noise in the training set which obviously can not be found in the validation set. We can conclude that whenever there is an increasing gap between our train error and our validation error we are overfitting. We would now choose the parameters according to the epoch where our model achieves the best results in both of our sets. This will then be our final model. In order to give an unbiased performance measure, we measure the accuracy of our best model on the so far unseen test set. This final performance evaluation will then be the true accuracy of our model. 


