---
layout: post
title:  "Learning in a neural network"
date:   2016-02-25
description: "What makes neural networks so powerful? How does a neural network learn?"
---
**The universal approximation theorem states that a feed-forward neural network (NN) with at least one single hidden layer can approximate any continuous function to any desired degree of accuracy.** This theorem was well known by people in the community but was proven by Cybenko et. al. for sigmoid activation functions in 1989. It has later been strengthened by Hornik et. al. to be true regardless of the activation function used as long as it may be any continuous nonconstant function. This is actually an astonishing fact! There are many difficult functions one might come up with e.g. a function which associates a picture of an object with a label, one which summarises a book, or one which chooses better moves in Go than a human might do. This means that whenever we fail to find the correct parameters for such a NN we might need to increase the number of neurons in our network to achieve a higher complexity of our model or we need to review the algorithm used for learning because it didn't lead us to the correct solution. The algorithm used to train a NN is named a learning algorithm (LA). Fortunately, we indeed have powerful LAs to train NNs. 

The ability to learn from its environment is one of the most important properties of a NN. A NN learns through an iterative modification of its weights and bias parameters. Different types of learning may achieve such a goal in different ways. A definition put forare yward by Haykin implies first that the NN is exposed to a simulated environment. It then undergoes changes in its free parameters in order to respond in a new way to the environment. There exist various types of LAs which bring different advantages and disadvantages for different types of NN architectures, as well as, for different types of problems. The main goal of today's NN community is to discover and understand new LAs which improve the performance of NNs. The LA may accept an existing configuration of the network and will compare the expected result and actual result of the NN to provide adjusted weights and biases to enhance its accuracy. Depending on the complexity of the model beeing simulated the underlying learning rule in the LA might be as simple as the Mean Squared Error (MSE) of an objective function, but not all LAs are based on an objective function. 

The feedback which a NN receives from its environment can be categorized into three main models of learning. The three main types of learning are Unsupervised Learning (UL), Supervised Learning (SL), and Reinforcement Learning (RL). SL is the easiest model to understand. In SL, both the input and the correct outputs are already provided. In this scenario, the LA can be interpreted as a kind of teacher. The NN processes the input and compares its predictions with the desired outputs. The LA algorithm then iteratively makes minor adjustments to the parameters to steadily improve the accuracy of the NN. For this approach to be successful a few key aspects need to be fulfilled. First, the size of the NN in terms of layers and neurons needs to be big enough to actually match the complexity of the problem. Second, the LA is appropriate for the NN, as well as, the problem at hand. Third, there are enough samples in our data available for the LA to achieve its goal. Especially in SL, the LA is not as important as one might like to believe. It has been shown how LAs tend to become less important as soon as they are applied to massive amounts of data. This notion has lead to the recent success of computationally cheap LAs over more expensive ones. Especially since we have nowadays very powerful computer hardware, as well as, giant data sets to operate on.

